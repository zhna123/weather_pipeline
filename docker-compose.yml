version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: postgres_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "5050:80"
    depends_on:
      - postgres
    restart: always
  airflow-init:
    image: apache/airflow:2.7.2
    container_name: airflow_init
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/weather
    entrypoint: >
      /bin/bash -c "airflow db init && airflow users create 
      --username admin 
      --firstname Airflow 
      --lastname Admin 
      --role Admin 
      --email admin@example.com 
      --password admin"
    restart: on-failure

  airflow-webserver:
    build: ./airflow
    container_name: airflow_webserver
    env_file:  # Load environment variables from .env
      - .env
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags  # Mount DAGs
      - ./scripts:/opt/weather_pipeline/scripts  # Mount scripts
      - ./dbt:/opt/weather_pipeline/dbt  # Mount dbt folder
      - ./data:/opt/weather_pipeline/data  # Mount the CSV folder
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/weather
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
    entrypoint: >
      /bin/bash -c "airflow webserver"
    restart: always

  airflow-scheduler:
    build: ./airflow
    container_name: airflow_scheduler
    env_file:  # Load environment variables from .env
      - .env
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/weather
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./airflow/dags:/opt/airflow/dags  # Mount DAGs
      - ./scripts:/opt/weather_pipeline/scripts  # Mount scripts
      - ./dbt:/opt/weather_pipeline/dbt  # Mount dbt folder
      - ./data:/opt/weather_pipeline/data  # Mount the CSV folder
    entrypoint: >
      /bin/bash -c "airflow scheduler"
    restart: always

volumes:
  pgdata:
